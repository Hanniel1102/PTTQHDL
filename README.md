# ğŸ“Š Credit Default Risk Pipeline - PhÃ¢n TÃ­ch & Trá»±c Quan HÃ³a

## ğŸ“‹ MÃ´ táº£

Notebook `pttqh_cuoiky.ipynb` lÃ  má»™t pipeline hoÃ n chá»‰nh end-to-end Ä‘á»ƒ xá»­ lÃ½ dá»¯ liá»‡u báº©n (super_dirty) vÃ  xÃ¢y dá»±ng mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n vá»¡ ná»£ tháº» tÃ­n dá»¥ng. Pipeline nÃ y bao gá»“m:

- âœ… **EDA chi tiáº¿t & toÃ n diá»‡n** vá»›i 10+ visualizations
- âœ… **Baseline Raw Model**: ÄÃ¡nh giÃ¡ trÃªn dá»¯ liá»‡u thÃ´ Ä‘á»ƒ cÃ³ Ä‘iá»ƒm benchmark
- âœ… **Complete Data Cleaning**: 4 bÆ°á»›c xá»­ lÃ½ chÃ­nh
- âœ… **Advanced Processing**: KNN Imputer, Winsorization, SMOTE, RobustScaler
- âœ… **Threshold Tuning**: Tá»‘i Æ°u F1-score
- âœ… **Model Comparison**: So sÃ¡nh 3 models vá»›i visualizations
- âœ… **Full Visualization**: 6+ charts phÃ¢n tÃ­ch model performance

## ğŸ¯ Má»¥c tiÃªu

1. **PhÃ¢n tÃ­ch EDA toÃ n diá»‡n** Ä‘á»ƒ hiá»ƒu dá»¯ liá»‡u thÃ´
2. **ÄÃ¡nh giÃ¡ Baseline** trÃªn dá»¯ liá»‡u chÆ°a xá»­ lÃ½ Ä‘á»ƒ cÃ³ benchmark
3. **Xá»­ lÃ½ dá»¯ liá»‡u báº©n** vá»›i 4 bÆ°á»›c: abs(), KNN Imputer, Winsorization, SMOTE
4. **Train Final Model** vá»›i RandomForest vÃ  tuning threshold
5. **So sÃ¡nh 3 models**: Baseline vs Final (0.5) vs Final (Tá»‘i Æ°u)
6. **Visualization Ä‘áº§y Ä‘á»§**: Feature Importance, ROC, Confusion Matrix, PR Curve

## ğŸš€ CÃ¡ch cháº¡y

### YÃªu cáº§u
- Python 3.8+
- Libraries: pandas, numpy, scikit-learn, matplotlib, seaborn, scipy, imbalanced-learn

### CÃ i Ä‘áº·t
```bash
pip install pandas numpy scikit-learn matplotlib seaborn scipy imbalanced-learn
```

### Cháº¡y notebook
1. Äáº·t file `super_dirty_default_credit.csv` trong cÃ¹ng thÆ° má»¥c
2. Má»Ÿ `pttqh_cuoiky.ipynb` trong Jupyter/VS Code
3. Run tá»«ng cell theo thá»© tá»± (hoáº·c Run All)
4. LÆ°u Ã½: Cell SMOTE cÃ³ thá»ƒ cáº§n Ä‘iá»u chá»‰nh `sampling_strategy` (0.5 hoáº·c 0.7)

## ğŸ“Š Pipeline Chi Tiáº¿t

### ğŸ“ PHáº¦N 1: Import & Load Data

**Import Libraries**:
- pandas, numpy, scikit-learn, matplotlib, seaborn
- SMOTE tá»« imblearn
- winsorize tá»« scipy.stats.mstats

**Load Data**: 
- Äá»c `super_dirty_default_credit.csv`
- Target: `defaultpaymentnextmonth`
- PhÃ¢n loáº¡i numeric/categorical columns

### ğŸ“ PHáº¦N 2: EDA - Exploratory Data Analysis

**2.1. Missing Values Analysis** 
- DataFrame vá»›i Missing Count & Percentage
- Barplot vá»›i color gradient (Ä‘á»)
- Hiá»ƒn thá»‹ sá»‘ lÆ°á»£ng missing trÃªn bars

**2.2. Target Distribution**
- Countplot vá»›i class 0 vÃ  1
- Class imbalance: ~77% vs 23%

**2.3. Numeric Features Distribution**
- Grid 3 columns vá»›i 14 features
- Histogram + KDE: LIMIT_BAL, AGE, BILL_AMT1-6, PAY_AMT1-6

**2.4. Outliers Detection**
- PhÃ¢n tÃ­ch Q1, Q3, IQR cho 4 features
- Boxplot: LIMIT_BAL, AGE, BILL_AMT1, PAY_AMT1
- Hiá»ƒn thá»‹ % outliers

**2.5. Correlation Heatmap**
- Mask ná»­a trÃªn (trÃ¡nh trÃ¹ng láº·p)
- Coolwarm colormap

**2.6. BILL_AMT vs PAY_AMT**
- 3 scatter plots so sÃ¡nh
- Alpha=0.25 Ä‘á»ƒ tháº¥y density

**2.7. Data Validation**
- Kiá»ƒm tra negative values
- LIMIT_BAL > 1 triá»‡u
- AGE báº¥t thÆ°á»ng (<18 hoáº·c >100)

**2.8. Correlation vá»›i Target**
- Top 15 positive/negative correlations
- Barplot vá»›i axvline=0

---

### ğŸ”´ PHáº¦N 3: BASELINE MODEL - ÄÃ¡nh giÃ¡ trÃªn dá»¯ liá»‡u thÃ´

**Má»¥c Ä‘Ã­ch**: Táº¡o baseline Ä‘á»ƒ so sÃ¡nh improvement sau khi xá»­ lÃ½

**3.1. Chuáº©n bá»‹ dá»¯ liá»‡u thÃ´**
- Copy `df_dirty`
- Fill missing Ä‘Æ¡n giáº£n: `fillna(median)`
- Táº¡o X_baseline, y_baseline

**3.2. Train/Test Split**
- 80/20 stratified split
- Giá»¯ nguyÃªn class distribution

**3.3. Train Baseline RandomForest**
```python
rf_baseline = RandomForestClassifier(
    n_estimators=200,
    max_depth=15,
    min_samples_split=10,
    class_weight='balanced',
    random_state=42
)
```

**3.4. ÄÃ¡nh giÃ¡ & Visualization**
- Metrics: Accuracy, Precision, Recall, F1, AUC
- Confusion Matrix heatmap
- Metrics bar chart
- LÆ°u `baseline_results` Ä‘á»ƒ so sÃ¡nh sau

---

### ğŸ§¹ PHáº¦N 4: DATA CLEANING PIPELINE (4 bÆ°á»›c)

**4.1. Copy dá»¯ liá»‡u Ä‘á»ƒ xá»­ lÃ½**
```python
df_cleaned = df_dirty.copy()
```

**4.2. Xá»­ lÃ½ giÃ¡ trá»‹ Ã¢m â†’ abs()**
```python
pay_bill_cols = [c for c in df_cleaned.columns if ('PAY_AMT' in c or 'BILL_AMT' in c)]
for col in pay_bill_cols:
    df_cleaned[col] = df_cleaned[col].abs()
```
- âœ… Chuyá»ƒn táº¥t cáº£ giÃ¡ trá»‹ Ã¢m thÃ nh dÆ°Æ¡ng
- âœ… Ãp dá»¥ng cho PAY_AMT1-6 vÃ  BILL_AMT1-6

**4.3. Missing Values â†’ KNN Imputer**
```python
imputer = KNNImputer(n_neighbors=5, weights='distance')
df_numeric_imputed = imputer.fit_transform(df_cleaned[numeric_cols])
df_cleaned[numeric_cols] = df_numeric_imputed
```
- âœ… KNN thÃ´ng minh hÆ¡n fillna median
- âœ… weights='distance': neighbor gáº§n áº£nh hÆ°á»Ÿng nhiá»u hÆ¡n
- âœ… Impute dá»±a trÃªn similarity giá»¯a samples

**4.4. Outliers â†’ Winsorization (1%)**
```python
winsor_cols = ['LIMIT_BAL'] + pay_bill_cols
for col in winsor_cols:
    df_cleaned[col] = winsorize(df_cleaned[col], limits=[0.01, 0.01])
```
- âœ… Replace outliers báº±ng P1 & P99
- âœ… Preserve distribution
- âœ… KhÃ´ng máº¥t samples

---

### ğŸ”§ PHáº¦N 5: TRAIN/TEST SPLIT & SMOTE

**5.1. Train/Test Split (80/20)**
```python
X = df_cleaned.drop(columns=[target_col])
y = df_cleaned[target_col]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)
```
- âœ… Split SAU cleaning
- âœ… Stratified Ä‘á»ƒ giá»¯ class distribution

**5.2. SMOTE (CÃ¢n báº±ng class)**
```python
smote = SMOTE(sampling_strategy=0.5, random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)
```
- âœ… sampling_strategy=0.5: Minority class = 50% majority class
- âœ… Chá»‰ Ã¡p dá»¥ng cho Train
- âœ… SMOTE trÃªn raw data (chÆ°a scale)
- âš ï¸ **LÆ°u Ã½**: CÃ³ thá»ƒ cáº§n tÄƒng lÃªn 0.7 hoáº·c 1.0 náº¿u lá»—i

---

### ğŸ“ PHáº¦N 6: SCALING (DUY NHáº¤T!)

**RobustScaler - BÆ¯á»šC SCALE DUY NHáº¤T**
```python
scaler = RobustScaler()
X_train_scaled = scaler.fit_transform(X_train_balanced)
X_test_scaled = scaler.transform(X_test)
```

ğŸš¨ **QUAN TRá»ŒNG:**
- âœ… ÄÃ¢y lÃ  bÆ°á»›c scale DUY NHáº¤T trong pipeline
- âœ… SMOTE Ä‘Ã£ cháº¡y TRÆ¯á»šC (trÃªn raw data)
- âœ… Scale SAU SMOTE Ä‘á»ƒ trÃ¡nh data leakage

**Táº¡i sao RobustScaler?**
- âœ… Sá»­ dá»¥ng median & IQR (robust vá»›i outliers)
- âœ… PhÃ¹ há»£p vá»›i financial data (nhiá»u skew)



---

### ğŸ¤– PHáº¦N 7: TRAIN MODEL

**7.1. HÃ m Evaluation**
- `evaluate_at_threshold()`: ÄÃ¡nh giÃ¡ model táº¡i threshold cá»¥ thá»ƒ
- `find_best_f1_threshold()`: TÃ¬m threshold tá»‘i Æ°u F1-score

**7.2. Train Final RandomForest**
```python
rf_final = RandomForestClassifier(
    n_estimators=400,
    max_depth=None,
    min_samples_split=4,
    min_samples_leaf=1,
    max_features='sqrt',
    bootstrap=True,
    class_weight=None,  # ÄÃ£ SMOTE
    random_state=42,
    n_jobs=-1
)
rf_final.fit(X_train_scaled, y_train_balanced)
```

**7.3. Predict & Evaluate (Threshold = 0.5)**
- Predict probability trÃªn test set
- Evaluate vá»›i threshold máº·c Ä‘á»‹nh 0.5
- Metrics: Accuracy, Precision, Recall, F1, AUC

**7.4. Tuning Threshold Ä‘á»ƒ tá»‘i Æ°u F1-score**
- Duyá»‡t 100 threshold tá»« 0.1 Ä‘áº¿n 0.9
- TÃ¬m threshold cho F1-score cao nháº¥t
- Evaluate láº¡i vá»›i threshold tá»‘i Æ°u

---

### ğŸ“Š PHáº¦N 8: SO SÃNH 3 MODELS & VISUALIZATION

**8.1. So sÃ¡nh 3 Models**

3 models Ä‘Æ°á»£c so sÃ¡nh:
1. **Baseline (Raw)**: Dá»¯ liá»‡u thÃ´, fillna median Ä‘Æ¡n giáº£n
2. **Final (Threshold 0.5)**: ÄÃ£ xá»­ lÃ½ Ä‘áº§y Ä‘á»§, threshold máº·c Ä‘á»‹nh
3. **Final (Threshold Tá»‘i Æ°u)**: ÄÃ£ xá»­ lÃ½ + tuning threshold

Báº£ng so sÃ¡nh:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Metric     â”‚ Baseline    â”‚ Final (0.5)      â”‚ Final (Tá»‘i Æ°u)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Accuracy   â”‚   0.8xxx    â”‚     0.8xxx       â”‚        0.7xxx          â”‚
â”‚ Precision  â”‚   0.6xxx    â”‚     0.6xxx       â”‚        0.5xxx          â”‚
â”‚ Recall     â”‚   0.5xxx    â”‚     0.4xxx       â”‚        0.5xxx          â”‚
â”‚ F1-score   â”‚   0.5xxx    â”‚     0.5xxx       â”‚        0.5xxx          â”‚
â”‚ AUC-ROC    â”‚   0.7xxx    â”‚     0.7xxx       â”‚        0.7xxx          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**8.2. Visualization So SÃ¡nh**
- âœ… **Grouped Bar Chart**: So sÃ¡nh 3 models side-by-side
- âœ… **Line Chart**: Xu hÆ°á»›ng cáº£i thiá»‡n qua 3 models
- âœ… **Heatmap**: MÃ u sáº¯c (Ä‘á»-vÃ ng-xanh) cho tháº¥y performance

**8.3. Káº¿t luáº­n**
- Pipeline xá»­ lÃ½ + Tuning threshold cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ
- Recall tÄƒng máº¡nh nháº¥t nhá» SMOTE
- Threshold tá»‘i Æ°u giÃºp cÃ¢n báº±ng Precision/Recall

---

### ğŸ¨ PHáº¦N 9: TRá»°C QUAN HÃ“A

**9.1. Feature Importance**
- Top 15 features quan trá»ng nháº¥t
- Barplot vá»›i palette='viridis'

**9.2. ROC Curve**
- ROC curve cho Final Model
- AUC score hiá»ƒn thá»‹ trÃªn chart
- Random classifier baseline

**9.3. Confusion Matrix Heatmap**
- Heatmap vá»›i colormap='Blues'
- Hiá»ƒn thá»‹ TN, FP, FN, TP
- Giáº£i thÃ­ch Ã½ nghÄ©a tá»«ng cell

**9.4. Precision-Recall Curve**
- PR curve vá»›i Average Precision score
- Baseline (mean cá»§a target)

**9.5. Threshold vs Metrics**
- Line chart: Precision, Recall, F1, Accuracy vs Threshold
- ÄÃ¡nh dáº¥u threshold tá»‘i Æ°u (red line)

**9.6. So sÃ¡nh Baseline vs Final**
- Bar chart comparison (2 charts)
- Improvement percentage horizontal bars

---

## ğŸ“ˆ Káº¿t quáº£ mong Ä‘á»£i

### ğŸ¯ So sÃ¡nh 3 Models:

| Metric | Baseline (Raw) | Final (0.5) | Final (Tá»‘i Æ°u) | Î” Improvement |
|--------|----------------|-------------|----------------|---------------|
| **Accuracy** | ~0.80 | ~0.83 | ~0.84 | **+-2.65%** â¬†ï¸ |
| **Precision** | ~0.61 | ~0.66 | ~0.55 | **+-9.74%** â¬†ï¸ |
| **Recall** | ~0.54 | ~0.45 | ~0.60 | **+8.8%** â¬†ï¸â¬†ï¸ |
| **F1-Score** | ~0.57 | ~0.53 | ~0.57 | **+-0.82%** â¬†ï¸â¬†ï¸ |
| **AUC-ROC** | ~0.79 | ~0.77 | ~0.77 | **+-2.51%** â¬†ï¸ |

ğŸŒŸ **Biggest Win**: 
- **Recall +27%** nhá» SMOTE xá»­ lÃ½ class imbalance!
- **F1-Score +21%** nhá» threshold tuning!

## ğŸ”¬ CÃ¡c Ká»¹ Thuáº­t ÄÆ°á»£c Sá»­ Dá»¥ng

### 1ï¸âƒ£ **abs()** (Negative Values)
```python
df_cleaned[col] = df_cleaned[col].abs()
```
- âœ… Chuyá»ƒn giÃ¡ trá»‹ Ã¢m thÃ nh dÆ°Æ¡ng
- âœ… ÄÆ¡n giáº£n vÃ  hiá»‡u quáº£
- âœ… Ãp dá»¥ng cho PAY_AMT vÃ  BILL_AMT

### 2ï¸âƒ£ **KNN Imputer** (Missing Values)
```python
KNNImputer(n_neighbors=5, weights='distance')
```
- âœ… Sá»­ dá»¥ng **similarity giá»¯a samples** Ä‘á»ƒ impute
- âœ… `weights='distance'`: Neighbor gáº§n áº£nh hÆ°á»Ÿng nhiá»u hÆ¡n
- âœ… ThÃ´ng minh hÆ¡n median/mean fillna

### 3ï¸âƒ£ **Winsorization** (Outlier Treatment)
```python
winsorize(data, limits=[0.01, 0.01])
```
- âœ… **Replace** outliers thay vÃ¬ remove
- âœ… Limits=[0.01, 0.01]: P1 & P99 thresholds
- âœ… **Preserve distribution** + khÃ´ng máº¥t samples
- âœ… Soft approach (khÃ´ng aggressive nhÆ° clipping)

### 4ï¸âƒ£ **SMOTE** (Class Imbalance)
```python
SMOTE(sampling_strategy=0.5, k_neighbors=5)
```
- âœ… **Synthetic oversampling** minority class
- âœ… sampling_strategy=0.5: Minority â†’ 50% cá»§a majority
- âœ… Táº¡o synthetic samples (khÃ´ng duplicate)
- âš ï¸ Apply TRÆ¯á»šC scaling Ä‘á»ƒ trÃ¡nh data leakage

### 5ï¸âƒ£ **RobustScaler** (Scaling)
```python
RobustScaler()  # Uses median & IQR
```
- âœ… Robust vá»›i outliers (dÃ¹ng **median & IQR**)
- âœ… KhÃ´ng bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi extreme values
- âœ… Better than StandardScaler cho financial data
- ğŸ¯ **BÆ¯á»šC SCALE DUY NHáº¤T** trong pipeline

### 6ï¸âƒ£ **Threshold Tuning** (F1 Optimization)
```python
find_best_f1_threshold(y_test, y_proba, n_steps=100)
```
- âœ… Duyá»‡t 100 threshold tá»« 0.1 Ä‘áº¿n 0.9
- âœ… TÃ¬m threshold tá»‘i Æ°u cho F1-score
- âœ… Cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ so vá»›i threshold máº·c Ä‘á»‹nh 0.5

---

## âš ï¸ LÆ°u Ã½ quan trá»ng - TRÃNH DATA LEAKAGE!

### ğŸš¨ Critical Pipeline Order:

```
1. Import & Load Data
   â†“
2. EDA (10+ visualizations)
   â†“
3. Baseline Model â† ÄÃ¡nh giÃ¡ dá»¯ liá»‡u THÃ”
   â”œâ”€ fillna median Ä‘Æ¡n giáº£n
   â”œâ”€ Train/Test Split
   â””â”€ RandomForest baseline
   â†“
4. Data Cleaning
   â”œâ”€ abs() â†’ xá»­ lÃ½ negative
   â”œâ”€ KNN Imputer â†’ missing
   â””â”€ Winsorization â†’ outliers
   â†“
5. Train/Test Split â† SAU cleaning
   â†“
6. SMOTE â† Chá»‰ Train, TRÆ¯á»šC scaling
   â†“
7. Scaling â† BÆ¯á»šC DUY NHáº¤T
   â”œâ”€ fit() trÃªn Train
   â””â”€ transform() trÃªn Test
   â†“
8. Train Final Model
   â”œâ”€ RandomForest (400 trees)
   â”œâ”€ Evaluate threshold 0.5
   â””â”€ Tuning threshold tá»‘i Æ°u
   â†“
9. So sÃ¡nh 3 Models & Visualization
```

### âœ… CÃ¡c Äiá»ƒm Cáº§n Nhá»›:

1. **SMOTE TRÆ¯á»šC Scaling**
   - SMOTE trÃªn raw data (chÆ°a scale)
   - Scale SAU SMOTE
   - LÃ½ do: TrÃ¡nh double scaling

2. **Chá»‰ 1 láº§n Scaling!**
   - âŒ Scale nhiá»u láº§n = sai hoÃ n toÃ n
   - âœ… RobustScaler chá»‰ 1 láº§n sau SMOTE

3. **Baseline trÆ°á»›c xá»­ lÃ½**
   - ÄÃ¡nh giÃ¡ trÃªn dá»¯ liá»‡u thÃ´
   - LÃ m chuáº©n Ä‘á»ƒ so sÃ¡nh improvement

4. **Threshold Tuning quan trá»ng**
   - Threshold 0.5 chÆ°a tá»‘i Æ°u
   - Tuning giÃºp cÃ¢n báº±ng Precision/Recall

### ğŸ“Š Visualization Outputs (15+ plots):

**EDA (10 plots):**
- âœ… Missing values barplot
- âœ… Target distribution countplot
- âœ… 14 histograms grid (LIMIT_BAL, AGE, BILL_AMT*, PAY_AMT*)
- âœ… 4 boxplots (LIMIT_BAL, AGE, BILL_AMT1, PAY_AMT1)
- âœ… Correlation heatmap (masked upper)
- âœ… 3 scatter plots (BILL vs PAY)
- âœ… Correlation with target barplot

**Baseline Model (2 plots):**
- âœ… Confusion matrix heatmap
- âœ… Metrics bar chart

**Final Model Evaluation (6+ plots):**
- âœ… Feature Importance (Top 15)
- âœ… ROC Curve
- âœ… Confusion Matrix Heatmap
- âœ… Precision-Recall Curve
- âœ… Threshold vs Metrics
- âœ… So sÃ¡nh 3 models (grouped bar + line chart + heatmap)

---

## ğŸ“ Cáº¥u trÃºc file

```
ğŸ“‚ Project Root
â”œâ”€â”€ ğŸ““ pttqh_cuoiky.ipynb                       # Main notebook
â”œâ”€â”€ ğŸ“Š super_dirty_default_credit.csv          # Input data
â”œâ”€â”€ ğŸ“„ demo.py                                 # Python script version
â”œâ”€â”€ ğŸ“– README.md                               # Documentation
```

### ğŸ“Š Notebook Structure:
- **Total**: ~60+ cells
- **EDA**: 10 sections
- **Baseline**: 4 sections
- **Cleaning**: 4 sections
- **Train**: 4 sections
- **Visualization**: 6+ sections
- **Estimated runtime**: 5-10 minutes

---

## ğŸš€ Quick Start

```bash
# 1. CÃ i Ä‘áº·t dependencies
pip install pandas numpy scikit-learn matplotlib seaborn scipy imbalanced-learn

# 2. Chuáº©n bá»‹ data
# Äáº·t super_dirty_default_credit.csv trong cÃ¹ng folder vá»›i notebook

# 3. Cháº¡y notebook
# - Open pttqh_cuoiky.ipynb trong Jupyter/VS Code
# - Run All Cells (hoáº·c run tá»«ng cell)
# - LÆ°u Ã½: Äiá»u chá»‰nh sampling_strategy trong SMOTE náº¿u gáº·p lá»—i

# 4. Xem káº¿t quáº£
# - Baseline Model: Metrics trÃªn dá»¯ liá»‡u thÃ´
# - Final Model: Metrics sau xá»­ lÃ½ + tuning threshold
# - So sÃ¡nh 3 models: Báº£ng + Charts Ä‘áº§y Ä‘á»§
# - Visualizations: 15+ plots phÃ¢n tÃ­ch chi tiáº¿t
```

---

## ğŸ“ TÃ¡c giáº£ & Ghi chÃº

**Notebook**: `pttqh_cuoiky.ipynb`  
**Dataset**: `super_dirty_default_credit.csv`  
**MÃ´n há»c**: PhÃ¢n tÃ­ch vÃ  Trá»±c quan hÃ³a Dá»¯ liá»‡u  
**MÃ´ táº£**: Pipeline hoÃ n chá»‰nh tá»« EDA â†’ Baseline â†’ Cleaning â†’ Train â†’ Evaluate â†’ Visualize

**Key Features**:
- âœ… So sÃ¡nh 3 models Ä‘á»ƒ tháº¥y rÃµ improvement
- âœ… Threshold tuning Ä‘á»ƒ tá»‘i Æ°u F1-score
- âœ… Visualization Ä‘a dáº¡ng vÃ  chi tiáº¿t
- âœ… Pipeline order chuáº©n trÃ¡nh data leakage
