# ğŸ“Š Credit Default Prediction: Dirty Data Cleaning Pipeline

## ğŸ“‹ MÃ´ táº£

Notebook `credit_default_dirty_full_pipeline.ipynb` lÃ  má»™t pipeline hoÃ n chá»‰nh Ä‘á»ƒ xá»­ lÃ½ dá»¯ liá»‡u siÃªu báº©n vÃ  xÃ¢y dá»±ng mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n vá»¡ ná»£ tháº» tÃ­n dá»¥ng. Pipeline nÃ y bao gá»“m:

- **EDA chi tiáº¿t** trÃªn dá»¯ liá»‡u báº©n (missing 25%, outliers, noise, corruption)
- **Baseline Raw**: ÄÃ¡nh giÃ¡ model ngay sau EDA (trÃªn dá»¯ liá»‡u báº©n)
- **Xá»­ lÃ½ Ä‘áº§y Ä‘á»§ corruption**: Missing, outliers, label flipping, shuffle, noise, negative values
- **Feature Engineering + Scaling + Feature Selection**
- **So sÃ¡nh 3 models**: Raw Baseline vs Clean Baseline vs Final Model

## ğŸ¯ Má»¥c tiÃªu

- KhÃ´i phá»¥c dá»¯ liá»‡u báº©n vá» tráº¡ng thÃ¡i gáº§n ban Ä‘áº§u
- ÄÃ¡nh giÃ¡ impact cá»§a tá»«ng bÆ°á»›c preprocessing
- XÃ¢y dá»±ng mÃ´ hÃ¬nh tá»‘i Æ°u vá»›i performance cao

## ğŸš€ CÃ¡ch cháº¡y

### YÃªu cáº§u
- Python 3.7+
- Libraries: pandas, numpy, scikit-learn, matplotlib, seaborn

### CÃ i Ä‘áº·t
```bash
pip install pandas numpy scikit-learn matplotlib seaborn
```

### Cháº¡y notebook
1. Äáº·t file `super_dirty_default_credit.csv` trong cÃ¹ng thÆ° má»¥c
2. Má»Ÿ notebook trong Jupyter/VS Code
3. Run tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i (restart kernel trÆ°á»›c khi cháº¡y)

## ğŸ“Š CÃ¡c bÆ°á»›c chÃ­nh

### 1. EDA (Exploratory Data Analysis)
- PhÃ¢n tÃ­ch missing values, outliers, correlations
- PhÃ¢n bá»‘ target vÃ  features chÃ­nh
- PhÃ¡t hiá»‡n cÃ¡c váº¥n Ä‘á» dá»¯ liá»‡u báº©n

### 2. Baseline Raw
- Train RandomForest trÃªn dá»¯ liá»‡u báº©n (chá»‰ fill missing cÆ¡ báº£n)
- ÄÃ¡nh giÃ¡ performance baseline trÆ°á»›c xá»­ lÃ½

### 3. Data Cleaning Pipeline
- **Negative values**: Abs cho PAY_AMT, BILL_AMT
- **Missing values**: Median cho numeric, mode cho categorical
- **Outliers**: IQR clipping + percentile 99 cho LIMIT_BAL/AGE
- **Shuffle**: Rolling median smoothing
- **Noise**: Median filter
- **Label flipping**: Model-based detection vÃ  correction

### 4. Feature Engineering
- AVG_BILL, AVG_PAY, UTILIZATION, PAY_STAB
- Ãp dá»¥ng riÃªng biá»‡t trÃªn Train/Test (trÃ¡nh data leakage)

### 5. Scaling & Feature Selection
- RobustScaler (fit trÃªn Train)
- RandomForest feature importance (chá»‰ trÃªn Train)

### 6. Model Training & Comparison
- **Baseline Clean**: RF trÃªn dá»¯ liá»‡u sáº¡ch cÆ¡ báº£n
- **Final Model**: RF vá»›i full pipeline (FE + FS)
- So sÃ¡nh metrics vÃ  ROC curves

## ğŸ“ˆ Káº¿t quáº£ mong Ä‘á»£i

- **Raw Baseline**: ~0.75-0.80 AUC (dá»¯ liá»‡u báº©n)
- **Clean Baseline**: ~0.82-0.85 AUC (sau preprocessing cÆ¡ báº£n)
- **Final Model**: ~0.85-0.88 AUC (full pipeline)

## ğŸ“ Cáº¥u trÃºc file

```
â”œâ”€â”€ credit_default_dirty_full_pipeline.ipynb  # Main notebook
â”œâ”€â”€ super_dirty_default_credit.csv           # Input data (báº©n)
â””â”€â”€ README.md                                # This file
```
